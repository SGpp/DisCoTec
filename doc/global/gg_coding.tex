
\chapter{Datastructures and Implementation}
\label{sec:implementation}
In this chapter, we will describe in more detail some implementation
details like datastructures and algorithms, which are used in the
global gene version. The content of this chapter mainly concerns the
$x$-global version of \gene.

\section{Datastructures}
\label{sec:datastructures}

\subsection{\texttt{Matrix}}
\label{sec:matrix}
The \texttt{Matrix} type is used as a kind of abstract class for a
matrix. It defines the interfaces for the operations which can be done
with a matrix. The real storage of the data and the real
implementation of the functions is done in the
\texttt{StoreFullMatrixObject} type. The idea of this splitting was,
that in the future, when object-oriented structures are possible in
Fortran (Fortran 2003 and further in Fortran 2008), we can rewrite
these types as real classes with real relationship. Then
\texttt{Matrix} will be the only class which is used from outside and
all the storage details and even the fact if the matrix is Banded,
Diagonal or something else is hidden from the user, but determined
automatically by the class itself.


\subsection{\texttt{BandedMatrix}}
At the moment we need to tell in advance from the user side if a
matrix can be treated as banded or as full. This type is mainly used
for the gyromatrix in $x$-direction. This matrix is a band matrix with
a bandwidth determined by the gyroradius-to-gridspace ratio. For the
ions this is always much larger than for the electrons due to their
larger mass and therefore gyroradius.

This is like \texttt{Matrix} just an abstract interface class, the
storage and distribution details are hidden in the
\texttt{StoreBandedMatrixObject} type.

\subsection{\texttt{Vector}}
Like the other two types \texttt{Matrix} and \texttt{BandedMatrix}
this type is just for defining the interface. Storage and calculation
details are in the \texttt{StoreVectorObject} type.

\subsection{\texttt{StoreFullMatrixObject}}
A full matrix is stored in this object. As we want to be able to use
ScaLapack routines at some point in the code, we setup the storage
format in a way usable be these routines. This means, we are using the
twodimensional cyclic block distribution. This concerns the
distribution over the processes and the local storage of the local
parts of the matrix. 

First a processgrid is initialized, where in principle one could choose between three
possibilities of how to distribute the matrix over the processes. First
is to store blocks of columns (\texttt{MAT\_BLOCKS\_OF\_COLS}) on the processes, second is to store
blocks of rows (\texttt{MAT\_BLOCKS\_OF\_ROWS}) on the processes, and the third one to make subblocks
of the matrix (\texttt{MAT\_BOTH}) and distribute them over the processes. The last
possibility is not yet implemented, the first one is not tested, so
the default is to use blocks of rows.

The global view of the distribution is then:
\begin{equation}
  \label{eq:matrix}
  \left(\begin{array}{cccccccc}
    a_{11} &a_{12} &a_{13}& a_{14} & a_{15} & a_{16} & a_{17} & a_{18}\\
    a_{21} &a_{22} &a_{23}& a_{24} & a_{25} & a_{26} & a_{27} & a_{28}\\
    a_{31} &a_{32} &a_{33}& a_{34} & a_{35} & a_{36} & a_{37} & a_{38}\\
    a_{41} &a_{42} &a_{43}&a_{44}& a_{45} & a_{46} & a_{47} & a_{48}\\\hline
    a_{51} &a_{52} &a_{53}&a_{54} &a_{55}& a_{56} & a_{57} & a_{58}\\
    a_{61} &a_{62} &a_{63}&a_{64} &a_{65} &a_{66}& a_{67} & a_{68}\\
    a_{71} &a_{72} &a_{73}&a_{74} &a_{75} &a_{76} &a_{77}& a_{78}\\
    a_{81} &a_{82} &a_{83}&a_{84} &a_{85} &a_{86}  &a_{87} &a_{88}
  \end{array}\right)
\end{equation}

How is this matrix stored locally?
Although the ScaLapack storage format is quite complicated, it is
simplified in our case by the fact, that we use only a one-dimensional
process grid. This means in the case of blocks of rows (the default),
the storage is exactly as shown in the global view. But we can
nevertheless make use of the ScaLapack routines for the field
solver. These ScaLapack routines does not scale optimal in our
distribution, and for an extension to larger processor number in the
$x$-direction or in the 3D case, we have to rethink the distribution.

\subsection{\texttt{StoreBandedMatrixObject}}
For the storage of the \texttt{BandedMatrix} a self-defined storage
format has been chosen, as this was the easiest way to have all the
features we need. The data is distributed by columns, the number of
columns per process is given by the attribute
\texttt{ColsPerBlock}. The banded structure of the Matrix is
represented by the \texttt{UpperBandwidth} and \texttt{LowerBandwidth}
attribute. None of these includes the diagonal. The local 2D array in
which the data is stored has the dimensions
\begin{displaymath}
  \mathtt{NumberOfStoredRows} \times\mathtt{ColsPerBlock} 
\end{displaymath}
where
\texttt{NumberOfStoredRows}=\texttt{UpperBandwidth}+\texttt{LowerBandwidth}+1. How
an element from the global matrix maps to the local storage is given
by the following graph for a $8\times8$ matrix with \texttt{UpperBandwidth}=2 and
\texttt{LowerBandwidth}=1.
\begin{equation}
  \label{eq:matrix}
  \left(\begin{array}{cccc|cccc}
    a_{11} &a_{12} &a_{13}& 0\\
    a_{21} &a_{22} &a_{23}& a_{24} & 0\\
    0 &a_{32} &a_{33}& a_{34} & a_{35} & 0\\
    0 & 0 &a_{43} &a_{44}& a_{45} & a_{46} & 0\\
    0 & 0 &0 &a_{54} &a_{55}& a_{56} & a_{57} & 0\\
    0 & 0 & 0 &0 &a_{65} &a_{66}& a_{67} & a_{68}\\
    0 & 0 & 0 & 0 &0 &a_{76} &a_{77}& a_{78}\\
    0 & 0 & 0 & 0 & 0 &0 &a_{87} &a_{88}
  \end{array}\right)
\end{equation}
This matrix is stored in an $4\times8$ array if there is no
distribution over processes.
\begin{displaymath}
  \begin{array}{c}
    -\mathtt{UpperBandwidth}\\
    \vdots\\
    0\\
    \mathtt{LowerBandwidth}
  \end{array}
\left[
  \begin{array}{cccc|cccc}
    * & * & a_{13} &  a_{24} & a_{35} & a_{46} & a_{57} & a_{68}\\
    * & a_{12} & a_{23} & a_{34} & a_{45} & a_{56} & a_{67} & a_{78}\\
    a_{11} & a_{22} & a_{33} & a_{44} & a_{55} & a_{66} & a_{77} & a_{88}\\
    a_{21} & a_{32} & a_{43} & a_{54} & a_{65} & a_{76} & a_{87} & *\\
  \end{array}
\right]
\end{displaymath}
If one has a distribution over two processes the array is separated at
the indicated line. Then the local array just has an extent of
$4\times4$.

To convert global indices $(r,c)$ into indices $(i,j)$ in the
\texttt{localMatrix}, we have to perform the following transformation
\begin{displaymath}
  i=r-c\qquad\mbox{and}\qquad j=((c-1)\mod\mathtt{ColsPerBlock})+1
\end{displaymath}
The usual storage order in memory is column-major as usual in
Fortran. This means the values of one column are contiguous in
memory. But as one can imagine this is not ideal for dot product with
a vector. There a row-major storage order would be beneficial. Hence,
for improving performance, the user can store a matrix in row-major
order if it is known that the matrix will be used mainly for
matrix-vector multiplication as the gyromatrix. This attribute of the
matrix is given at initialization time of the matrix as an additional
argument.

If the matrix is stored in row-major order, the storage layout of the
matrix, defined in eq. (\ref{eq:matrix}) is
\begin{displaymath}
  \begin{array}{c}
    -\mathtt{LowerBandwidth}\\
    \vdots\\
    0\\
    \mathtt{UpperBandwidth}
  \end{array}
\left[
  \begin{array}{cccc|cccc}
    *     & a_{21} & a_{32} & a_{43} & a_{54} & a_{65} & a_{76} & a_{87}\\
    a_{11} & a_{22} & a_{33} & a_{44} & a_{55} & a_{66} & a_{77} & a_{88}\\
    a_{12} & a_{23} & a_{34} & a_{45} & a_{56} & a_{67} & a_{78} & *\\
    a_{13} & a_{24} & a_{35} & a_{46} & a_{57} & a_{68} & * & *
  \end{array}
\right]
\end{displaymath}
Here the transformation rules from global $(r,c)$ indices to
\texttt{localMatrix} indices $(i,j)$ are
\begin{displaymath}
  i=c-r\qquad\mbox{and}\qquad j=((r-1)\mod\mathtt{ColsPerBlock})+1
\end{displaymath}


\subsection{StoreVectorObject}
A vector is stored as a one dimensional array. It is trivially
distributed over the rows.
\begin{displaymath}
  \left(
  \begin{array}{c}
    c_1\\
    c_2\\
    c_3\\
    c_4\\
    \hline
    c_5\\
    c_6\\
    c_7\\
    c_8
  \end{array}\right)\Longrightarrow
\left[
  \begin{array}{cccc|cccc}
    c_1 & c_2 & c_3 & c_4 & c_5 & c_6 & c_7 & c_8
  \end{array}
\right]
\end{displaymath}

\subsection{Matrix-Vector multiplication}
This is the most relevant operation for the gyro-average and has to be
done very often. Therefore we optimized it. The gyromatrix is stored
in row-major order, so a row of the matrix is always local to one
processor. 
For a matrix-vector multiplication, the vector is first gathered on
all processes and then multiplied with the local rows. The resulting
vector is already correctly distributed over the processes.

If the matrix is not transposed, first the local parts of the
matrix-vector multiplication are calculated on all processes in
parallel. Then a reduction is done over the processes.

\subsection{Matrix-Matrix multiplication}
For the matrix-matrix multiplication there have to be distinguished
several cases, which are different in the implementation.
\begin{enumerate}
\item Matrix-Matrix multiplication with two full matrices
\item BandedMatrix-BandedMatrix multiplication
  At the moment only the case with first matrix in row-major order and
  second matrix in column-major order is implemented.
\item BandedMatrix-Matrix multiplication
  Here also only the case with the BandedMatrix in row-major order and
  the Matrix in column-major order is implemented. The result is
  stored in column-major order.
\end{enumerate}

\subsubsection{BandedMatrix-BandedMatrix multiplication}
First, we will have a look on this independent of the storage
format. The operation is 
\begin{displaymath}
  A\cdot B = R
\end{displaymath}
or with the matrices written explicitly, assuming a dimension of 6. We
also use for matrix $A$ \texttt{UpperBandwidth}=2 and
\texttt{LowerBandwidth}=1, for matrix $B$ \texttt{UpperBandwidth}=1
and \texttt{LowerBandwidth}=0.
\begin{equation}
  \label{eq:bmatbmatbmat}
  \left(\begin{array}{cccccc}
    r_{11} &r_{12} &r_{13}& r_{14} & 0 & 0\\
    r_{21} &r_{22} &r_{23}& r_{24} & r_{25} & 0\\
    0 &r_{32} &r_{33}& r_{34} & r_{35} & r_{36}\\\hline
    0 & 0 &r_{43}& r_{44} & r_{45} & r_{46} \\
    0 & 0 & 0 & r_{54} & r_{55} & r_{56} \\
    0 & 0 & 0 & 0 & r_{65} & r_{66}\\
  \end{array}\right) =
  \left(\begin{array}{cccccc}
    a_{11} &a_{12} &a_{13}& 0\\
    a_{21} &a_{22} &a_{23}& a_{24} & 0\\
    0 &a_{32} &a_{33}& a_{34} & a_{35} & 0\\\hline
    0 & 0 &a_{43} &a_{44}& a_{45} & a_{46} \\
    0 & 0 &0 &a_{54} &a_{55}& a_{56}\\
    0 & 0 & 0 &0 &a_{65} &a_{66}
  \end{array}\right)
\cdot
  \left(\begin{array}{cccccc}
    b_{11} &b_{12} & 0 & 0\\
    0 &b_{22} &b_{23}& 0 & 0\\
    0 & 0 &b_{33}& b_{34} & 0 & 0\\\hline
    0 & 0 & 0 &b_{44}& b_{45} & 0 \\
    0 & 0 & 0 & 0 &b_{55}& b_{56}\\
    0 & 0 & 0 & 0 & 0 &b_{66}
  \end{array}\right)
\end{equation}
The upper and lower bandwidths of the matrices $A$ and $B$ just add
and give the upper and lower bandwidth of the result matrix. In our
example case $R$ has \texttt{UpperBandwidth}=3 and
\texttt{LowerBandwidth}=1. 

The usual definition of the matrix-matrix multiplication in index form
is
\begin{displaymath}
  r_{ij}=\sum_{k=1}^N a_{ik} b_{kj}\qquad i,j\in\{1,\ldots,N\}
\end{displaymath}
We divide the full index space of $\{1,\ldots,N\}$ into $N_p$
intervals, one for each processor.
\begin{displaymath}
  I_p=\{(p-1)\frac{N}{N_p}+1,\ldots,p\frac{N}{N_p}\}\qquad p\in\{1,\ldots,N_p\}
\end{displaymath}
Then we can separate the sum into sums over the intervals and sum the
partial sums.
\begin{displaymath}
  r_{ij}=\sum_{p=1}^{N_p}\sum_{k\in I_p} a_{ik} b_{kj}\qquad i,j\in\{1,\ldots,N\}
\end{displaymath}
We also separate the different rows of the result matrix in the
intervals
\begin{equation}
  \label{eq:distr_mat}
  r_{ij}^{(s)}=\sum_{p=1}^{N_p}\sum_{k\in I_p} a_{ik}^{(s)}
  b_{kj}^{(p)}\qquad i\in I_s \wedge j\in\{1,\ldots,N\}
\end{equation}
where the upper index indicates the number of the processor where the
data is local.
Hence, we can only do calculations with data which is on the same
processor, otherwise we need communication.

We expand the $p$ sum in eq. (\ref{eq:distr_mat}) and get
\begin{equation}
  \label{eq:distr_mat_exp}
  r_{ij}^{(s)}=\sum_{k\in I_1} a_{ik}^{(s)}b_{kj}^{(1)}
  +\sum_{k\in I_2} a_{ik}^{(s)}b_{kj}^{(2)}
  +\ldots
  +\sum_{k\in I_{N_p}} a_{ik}^{(s)}b_{kj}^{({N_p})}
  \qquad i\in I_s \wedge j\in\{1,\ldots,N\}
\end{equation}
Only one summand of this expansion can be computed directly, due to
the locality of the data. For all other computations, we first have to
transfer a block of the $B$ matrix to the other processors.

In the computation of the dot product of two blocks (one subsum term in the
above sum) we have now to take into account the banded structure of
both matrices. This is done by constraining the index intervals to the
indices of the band. Therefore we define the column index set of band
matrix $M$ in row $i$ to be
\begin{equation}
  \label{eq:colindexset}
  \mathcal{B}_i(M)=\{i-\mathtt{LowerBandwidth}(M),i+\mathtt{UpperBandwidth}(M)\}
\end{equation}
and the row index set of a band matrix $M$ in column $j$ as
\begin{equation}
  \label{eq:rowindexset}
  \bar{\mathcal{B}}_j(M)=\{j-\mathtt{UpperBandwidth}(M),j+\mathtt{LowerBandwidth}(M)\}.
\end{equation}
The sum can then be rewritten by
\begin{equation}
  \label{eq:distr_mat}
  r_{ij}^{(s)}=\sum_{p=1}^{N_p}\sum_{k\in J_p} a_{ik}^{(s)}
  b_{kj}^{(p)}\qquad i\in J_s \wedge j\in\mathcal{B}_i(R)
\end{equation}
with the reduced index set
\begin{displaymath}
  J_p=I_p\cap\mathcal{B}_i(A)\cap\bar{\mathcal{B}}_j(B)
\end{displaymath}
In our example, we have for $p=1, N=8, N_p=2$
\begin{eqnarray*}
  I_1&=&\{1,2,3,4\}\\
  \mathcal{B}_1(A) &=& \{1-1,\ldots,1+2\}=\{0,1,2,3\}\\
  \bar{\mathcal{B}}_1(B) &=& \{1-1,\ldots,1+0\}=\{0,1\}\\
  J_1 &=& \{1,2,3,4\}\cap\{0,1,2,3\}\cap\{0,1\}=\{1\}
\end{eqnarray*}
and for $p=2$
\begin{eqnarray*}
  I_2&=&\{5,6,7,8\}\\
  \mathcal{B}_1(A) &=& \{1-1,\ldots,1+2\}=\{0,1,2,3\}\\
  \bar{\mathcal{B}}_1(B) &=& \{1-1,\ldots,1+0\}=\{0,1\}\\
  J_2 &=& \{5,6,7,8\}\cap\{0,1,2,3\}\cap\{0,1\}=\{\}
\end{eqnarray*}
Then we have for the $r_{11}$ element of the result matrix the
expression
\begin{displaymath}
  r_{11}^{(1)}=a_{11}^{(1)}b_{11}^{(1)}
\end{displaymath}

I will elaborate a bit more about the case where all three involved
matrices are stored in row-major (``C'') order. 
For each matrix, the rows are stored contiguously. The stored arrays
of the example matrices are then
\begin{displaymath}
  \mathtt{localMatrix}(A)=  \begin{array}{c}
    -1\\
    0\\
    1\\
    2
  \end{array}
\left[
  \begin{array}{ccc|ccc}
    *     & a_{21} & a_{32} & a_{43} & a_{54} & a_{65} \\
    a_{11} & a_{22} & a_{33} & a_{44} & a_{55} & a_{66} \\
    a_{12} & a_{23} & a_{34} & a_{45} & a_{56} & * \\
    a_{13} & a_{24} & a_{35} & a_{46} & * & * 
  \end{array}
\right]
\end{displaymath}
and
\begin{displaymath}
  \mathtt{localMatrix}(B)=  \begin{array}{c}
    0\\
    1
  \end{array}
\left[
  \begin{array}{ccc|ccc}
    b_{11} & b_{22} & b_{33} & b_{44} & b_{55} & b_{66} \\
    b_{12} & b_{23} & b_{34} & b_{45} & b_{56} & * 
  \end{array}
\right]
\end{displaymath}
We continously have to multiply the local block of matrix $A$ with the
received blocks from matrix $B$. We start with 
\begin{displaymath}
  \left(\begin{array}{cccccc}
    r_{11} &r_{12} &r_{13}& r_{14} & 0 & 0\\
    r_{21} &r_{22} &r_{23}& r_{24} & r_{25} & 0\\
    0 &r_{32} &r_{33}& r_{34} & r_{35} & r_{36}
  \end{array}\right) \stackrel{+}{\longleftarrow}
  \left(\begin{array}{ccc}
      a_{11} &a_{12} &a_{13} \\
      a_{21} &a_{22} &a_{23}\\
      0 &a_{32} &a_{33}
  \end{array}\right)
\cdot
  \left(\begin{array}{cccccc}
    b_{11} &b_{12} & 0 & 0 & 0 & 0\\
    0 &b_{22} &b_{23}& 0 & 0 & 0\\
    0 & 0 &b_{33}& b_{34} & 0 & 0
  \end{array}\right)
\end{displaymath}
and then
\begin{displaymath}
  \left(\begin{array}{cccccc}
    r_{11} &r_{12} &r_{13}& r_{14} & 0 & 0\\
    r_{21} &r_{22} &r_{23}& r_{24} & r_{25} & 0\\
    0 &r_{32} &r_{33}& r_{34} & r_{35} & r_{36}
  \end{array}\right) \stackrel{+}{\longleftarrow}
  \left(\begin{array}{ccc}
      0      & 0 & 0\\
      a_{24} & 0 & 0\\
      a_{34} & a_{35} & 0
  \end{array}\right)
\cdot
  \left(\begin{array}{cccccc}
    0 & 0 & 0 &b_{44}& b_{45} & 0 \\
    0 & 0 & 0 & 0 &b_{55}& b_{56}\\
    0 & 0 & 0 & 0 & 0 &b_{66}
  \end{array}\right)
\end{displaymath}
Or written with the stored blocks:
\begin{eqnarray*}
  p=0, I_0=\{1,2,3\}\\
  \left(\begin{array}{cccccc}
    r_{11} &r_{12} &r_{13}& r_{14} & 0 & 0\\
    r_{21} &r_{22} &r_{23}& r_{24} & r_{25} & 0\\
    0 &r_{32} &r_{33}& r_{34} & r_{35} & r_{36}
  \end{array}\right) \stackrel{+}{\longleftarrow}
\left[
  \begin{array}{ccc}
    *     & a_{21} & a_{32}  \\
    a_{11} & a_{22} & a_{33} \\
    a_{12} & a_{23} & a_{34}\\
    a_{13} & a_{24} & a_{35} 
  \end{array}
\right]*
\left[
  \begin{array}{ccc}
    b_{11} & b_{22} & b_{33} \\
    b_{12} & b_{23} & b_{34} 
  \end{array}
\right]
\end{eqnarray*}
and then
\begin{eqnarray*}
  p=1, I_1=\{4,5,6\}\\
  \left(\begin{array}{cccccc}
    r_{11} &r_{12} &r_{13}& r_{14} & 0 & 0\\
    r_{21} &r_{22} &r_{23}& r_{24} & r_{25} & 0\\
    0 &r_{32} &r_{33}& r_{34} & r_{35} & r_{36}
  \end{array}\right) \stackrel{+}{\longleftarrow}
\left[
  \begin{array}{ccc}
    *     & a_{21} & a_{32}  \\
    a_{11} & a_{22} & a_{33} \\
    a_{12} & a_{23} & a_{34} \\
    a_{13} & a_{24} & a_{35}
  \end{array}
\right]*
\left[
  \begin{array}{ccc}
    b_{44} & b_{55} & b_{66} \\
    b_{45} & b_{56} & * 
  \end{array}
\right]
\end{eqnarray*}

\subsubsection{BandedMatrix (column-major)-BandedMatrix(row-major) multiplication}
Another multiplication scheme, which involves a different algorithm is
the multiplication of a BandedMatrix in column-major format with a
BandedMatrix in row-major format.
The matrix equation for the given example is the
\begin{equation}
  \label{eq:bmatcbmatrbmatr}
  \left(\begin{array}{cccccc}
      r_{11} &r_{12} &r_{13}& r_{14} & 0 & 0\\
      r_{21} &r_{22} &r_{23}& r_{24} & r_{25} & 0\\
      0 &r_{32} &r_{33}& r_{34} & r_{35} & r_{36}\\\hline
      0 & 0 &r_{43}& r_{44} & r_{45} & r_{46} \\
      0 & 0 & 0 & r_{54} & r_{55} & r_{56} \\
      0 & 0 & 0 & 0 & r_{65} & r_{66}\\
    \end{array}\right) =
  \left(\begin{array}{ccc|ccc}
      a_{11} &a_{12} &a_{13}& 0\\
      a_{21} &a_{22} &a_{23}& a_{24} & 0\\
      0 &a_{32} &a_{33}& a_{34} & a_{35} & 0\\
      0 & 0 &a_{43} &a_{44}& a_{45} & a_{46} \\
      0 & 0 &0 &a_{54} &a_{55}& a_{56}\\
      0 & 0 & 0 &0 &a_{65} &a_{66}
    \end{array}\right)
  \cdot
  \left(\begin{array}{cccccc}
      b_{11} &b_{12} & 0 & 0\\
      0 &b_{22} &b_{23}& 0 & 0\\
      0 & 0 &b_{33}& b_{34} & 0 & 0\\\hline
      0 & 0 & 0 &b_{44}& b_{45} & 0 \\
      0 & 0 & 0 & 0 &b_{55}& b_{56}\\
      0 & 0 & 0 & 0 & 0 &b_{66}
    \end{array}\right)
\end{equation}
The only difference is the different parallelization of the $A$
matrix. But this difference has consequences in the algorithm.

Again we can write for the elements of the result matrix the matrix
product in index writing:
\begin{equation}
  \label{eq:distr_mat}
  r_{ij}^{(s)}=\sum_{p=1}^{N_p}\sum_{k\in I_p} a_{ik}^{(p)}
  b_{kj}^{(p)}\qquad i\in I_s \wedge j\in\{1,\ldots,N\}
\end{equation}

The algorithm for this multiplication is to multiply the respective
local submatrices on the processors and then reduce the results to the
correct processors (the first three rows to the first processor, the
second three rows to the second processor in the example). For the
subsums we have to take into account the banded structure of the
matrices as before. This is again done by using the reduced index set
$J_p$. The local result matrix is a bandedmatrix 
\begin{equation}
  \label{eq:distr_mat}
  r_{ij}^{(s)}=\sum_{p=1}^{N_p}\sum_{k\in J_p} a_{ik}^{(p)}
  b_{kj}^{(p)}\qquad i\in I_s \wedge j\in\{1,\ldots,N\}
\end{equation}
Written with the stored \texttt{localmatrix} array, we have
\begin{displaymath}
  \mathtt{localMatrix}(A)=  \begin{array}{c}
    -2\\
    -1\\
    0\\
    1
  \end{array}
\left[
  \begin{array}{ccc|ccc}
    * & * & a_{13} &  a_{24} & a_{35} & a_{46} \\
    * & a_{12} & a_{23} & a_{34} & a_{45} & a_{56} \\
    a_{11} & a_{22} & a_{33} & a_{44} & a_{55} & a_{66} \\
    a_{21} & a_{32} & a_{43} & a_{54} & a_{65} & * 
  \end{array}
\right]
\end{displaymath}
and
\begin{displaymath}
  \mathtt{localMatrix}(B)=  \begin{array}{c}
    0\\
    1
  \end{array}
\left[
  \begin{array}{ccc|ccc}
    b_{11} & b_{22} & b_{33} & b_{44} & b_{55} & b_{66} \\
    b_{12} & b_{23} & b_{34} & b_{45} & b_{56} & * 
  \end{array}
\right]
\end{displaymath}

\subsubsection{BandedMatrix (row-major)-BandedMatrix(column-major) $\rightarrow$ BandedMatrix(column-major) multiplication}
Another multiplication scheme, which involves a different algorithm is
the multiplication of a BandedMatrix in row-major format with a
BandedMatrix in column-major format and the result is written in column-major format.
The matrix equation for the given example is the
\begin{equation}
  \label{eq:bmatrbmatcbmatc}
  \left(\begin{array}{ccc|ccc}
      r_{11} &r_{12} &r_{13}& r_{14} & 0 & 0\\
      r_{21} &r_{22} &r_{23}& r_{24} & r_{25} & 0\\
      0 &r_{32} &r_{33}& r_{34} & r_{35} & r_{36}\\
      0 & 0 &r_{43}& r_{44} & r_{45} & r_{46} \\
      0 & 0 & 0 & r_{54} & r_{55} & r_{56} \\
      0 & 0 & 0 & 0 & r_{65} & r_{66}\\
    \end{array}\right) =
  \left(\begin{array}{cccccc}
      a_{11} &a_{12} &a_{13}& 0\\
      a_{21} &a_{22} &a_{23}& a_{24} & 0\\
      0 &a_{32} &a_{33}& a_{34} & a_{35} & 0\\ \hline
      0 & 0 &a_{43} &a_{44}& a_{45} & a_{46} \\
      0 & 0 &0 &a_{54} &a_{55}& a_{56}\\
      0 & 0 & 0 &0 &a_{65} &a_{66}
    \end{array}\right)
  \cdot
  \left(\begin{array}{ccc|ccc}
      b_{11} &b_{12} & 0 & 0\\
      0 &b_{22} &b_{23}& 0 & 0\\
      0 & 0 &b_{33}& b_{34} & 0 & 0\\
      0 & 0 & 0 &b_{44}& b_{45} & 0 \\
      0 & 0 & 0 & 0 &b_{55}& b_{56}\\
      0 & 0 & 0 & 0 & 0 &b_{66}
    \end{array}\right)
\end{equation}

We start again with the definition of the dot product of two matrices:
\begin{displaymath}
  r_{ij}=\sum_{k=1}^N a_{ik}b_{kj}\qquad i,j\in\{1,\ldots,N\}
\end{displaymath}
But now we do not divide the $k$ sum, as for one $i$ all $a_{ik}$ and
for one $j$ all $b_{kj}$ are local in the given storage formats. We
now have to separate the calculation of different $r_{ij}$. With the
usual division of the total index space $\{1,\ldots,N\}$ into $N_p$
subintervals $I_p$ with
\begin{displaymath}
  I_p=\{(p-1)\frac{N}{N_p}+1,\ldots,p\frac{N}{N_p}\}\qquad p\in\{1,\ldots,N_p\}
\end{displaymath}
we can write
\begin{displaymath}
  r_{ij}^{(s)}=\sum_{k=1}^N a_{ik}^{(p)}b_{kj}^{(s)}\qquad
  i\in I_p\wedge j\in I_s
\end{displaymath}
Only for $s=p$ we can do the calculation without communication, for
all other cases, we have to transfer parts of matrix $A$ from process
$p$ to process $s$. 

For the multiplication of the blocks, we have again to take into
account the banded structure of the matrices. Hence, we use again the
definitions (\ref{eq:colindexset}) and (\ref{eq:rowindexset}).
We get then
\begin{displaymath}
  r_{ij}^{(s)}=\sum_{k\in K_{ij}}^N a_{ik}^{(p)}b_{kj}^{(s)}\qquad
  i\in I_p\wedge j\in I_s
\end{displaymath}
with 
\begin{displaymath}
  K_{ij}=\{1,\ldots,N\}\cap\mathcal{B}_i(A)\cap\bar{\mathcal{B}}_j(B).
\end{displaymath}
And now additionally we can constrain the indices $i,j$ for the result
matrix, as we know already which entries in $R$ are zero just due to
the structure of the matrices $A$ and $B$.
There are two equivalent possibilities to write this, first
\begin{displaymath}
  r_{ij}^{(s)}=\sum_{k\in K_{ij}}^N a_{ik}^{(p)}b_{kj}^{(s)}\qquad
  i\in I_p\wedge j\in I_s\cap\mathcal{B}_i(R)
\end{displaymath}
and second
\begin{displaymath}
  r_{ij}^{(s)}=\sum_{k\in K_{ij}}^N a_{ik}^{(p)}b_{kj}^{(s)}\qquad
  j\in I_s\wedge i\in I_p\cap\bar{\mathcal{B}}_j(R)
\end{displaymath}

In a simplified algorithm, we can gather the matrix $A$ on all
processes and can then write the last equation as
\begin{displaymath}
  r_{ij}^{(s)}=\sum_{k\in K_{ij}}^N a_{ik}b_{kj}^{(s)}\qquad
  j\in I_s\wedge i\in\{1,\ldots,N\}\cap\bar{\mathcal{B}}_j(R)
\end{displaymath}


Written with the stored \texttt{localmatrix} array, we have
\begin{displaymath}
  \mathtt{localMatrix}(A)=  \begin{array}{c}
    -1\\
    0\\
    1\\
    2
  \end{array}
\left[
  \begin{array}{ccc|ccc}
    *     & a_{21} & a_{32} & a_{43} & a_{54} & a_{65} \\
    a_{11} & a_{22} & a_{33} & a_{44} & a_{55} & a_{66} \\
    a_{12} & a_{23} & a_{34} & a_{45} & a_{56} & * \\
    a_{13} & a_{24} & a_{35} & a_{46} & *     & * 
  \end{array}
\right]
\end{displaymath}
and
\begin{displaymath}
  \mathtt{localMatrix}(B)=  \begin{array}{c}
    -1\\
    0
  \end{array}
\left[
  \begin{array}{ccc|ccc}
    *     & b_{12} & b_{23} & b_{34} & b_{45} & b_{56} \\ 
    b_{11} & b_{22} & b_{33} & b_{44} & b_{55} & b_{66} \\
  \end{array}
\right]
\end{displaymath}
and
\begin{displaymath}
  \mathtt{localMatrix}(R)=  \begin{array}{c}
    -3\\
    -2\\
    -1 \\
    0\\
    1
  \end{array}
\left[
  \begin{array}{ccc|ccc}
    *     & *      & *     & r_{14} & r_{25} & r_{36} \\ 
    *     & *      & r_{13} & r_{24} & r_{35} & r_{46} \\ 
    *     & r_{12} & r_{23} & r_{34} & r_{45} & r_{56} \\ 
    r_{11} & r_{22} & r_{33} & r_{44} & r_{55} & r_{66} \\
    r_{21} & r_{32} & r_{43} & r_{54} & r_{65} & * \\ 
  \end{array}
\right]
\end{displaymath}


\subsubsection{BandedMatrix-Matrix multiplication}
The last case will be derived here in more detail.
\begin{equation}
  \label{eq:bmatmatmat}
  \left(\begin{array}{cccccc}
    r_{11} &r_{12} &r_{13}& r_{14} & r_{15} & r_{16}\\
    r_{21} &r_{22} &r_{23}& r_{24} & r_{25} & r_{26}\\
    r_{31} &r_{32} &r_{33}& r_{34} & r_{35} & r_{36}\\\hline
    r_{41} &r_{42} &r_{43}& r_{44} & r_{45} & r_{46} \\
    r_{51} &r_{52} &r_{53}& r_{54} & r_{55} & r_{56} \\
    r_{61} &r_{62} &r_{63}& r_{64} & r_{65} & r_{66}\\
  \end{array}\right) =
  \left(\begin{array}{cccccc}
    a_{11} &a_{12} &a_{13}& 0\\
    a_{21} &a_{22} &a_{23}& a_{24} & 0\\
    0 &a_{32} &a_{33}& a_{34} & a_{35} & 0\\\hline
    0 & 0 &a_{43} &a_{44}& a_{45} & a_{46} \\
    0 & 0 &0 &a_{54} &a_{55}& a_{56}\\
    0 & 0 & 0 &0 &a_{65} &a_{66}
  \end{array}\right)
\cdot
  \left(\begin{array}{cccccccc}
    b_{11} &b_{12} &b_{13}& b_{14} & b_{15} & b_{16}\\
    b_{21} &b_{22} &b_{23}& b_{24} & b_{25} & b_{26}\\
    b_{31} &b_{32} &b_{33}& b_{34} & b_{35} & b_{36}\\\hline
    b_{41} &b_{42} &b_{43}& b_{44} & b_{45} & b_{46}\\
    b_{51} &b_{52} &b_{53}& b_{54} & b_{55} & b_{56}\\
    b_{61} &b_{62} &b_{63}& b_{64} & b_{65} & b_{66}\\
  \end{array}\right)
\end{equation}
The usual definition of the matrix-matrix multiplication in index form
is
\begin{displaymath}
  r_{ij}=\sum_{k=1}^N a_{ik} b_{kj}\qquad i,j\in\{1,\ldots,N\}
\end{displaymath}
We divide the full index space of $\{1,\ldots,N\}$ into $N_p$
intervals, one for each processor.
\begin{displaymath}
  I_p=\{(p-1)\frac{N}{N_p}+1,\ldots,p\frac{N}{N_p}\}\qquad p\in\{1,\ldots,N_p\}
\end{displaymath}
Then we can separate the sum into sums over the intervals and sum the
partial sums.
\begin{displaymath}
  r_{ij}=\sum_{p=1}^{N_p}\sum_{k\in I_p} a_{ik} b_{kj}\qquad i,j\in\{1,\ldots,N\}
\end{displaymath}
We also separate the different rows of the result matrix in the
intervals
\begin{equation}
  \label{eq:distr_mat}
  r_{ij}^{(s)}=\sum_{p=1}^{N_p}\sum_{k\in I_p} a_{ik}^{(s)}
  b_{kj}^{(p)}\qquad i\in I_s \wedge j\in\{1,\ldots,N\}
\end{equation}
where the upper index indicates the number of the processor where the
data is local.
Hence, we can only do calculations with data which is on the same
processor, otherwise we need communication.

We expand the $p$ sum in eq. (\ref{eq:distr_mat}) and get
\begin{equation}
  \label{eq:distr_mat_exp}
  r_{ij}^{(s)}=\sum_{k\in I_1} a_{ik}^{(s)}b_{kj}^{(1)}
  +\sum_{k\in I_2} a_{ik}^{(s)}b_{kj}^{(2)}
  +\ldots
  +\sum_{k\in I_{N_p}} a_{ik}^{(s)}b_{kj}^{({N_p})}
  \qquad i\in I_s \wedge j\in\{1,\ldots,N\}
\end{equation}
Only one summand of this expansion can be computed directly, due to
the locality of the data. For all other computations, we first have to
transfer a block of the $b$ matrix to the other processors.

To overlay computation with communication we adopt the following
algorithm. Always initiate a non-blocking receive for the next block,
then send non-blocking the local block to the previous processor. Then
while waiting for the communication, do the local computation.

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "globalgene"
%%% End:
